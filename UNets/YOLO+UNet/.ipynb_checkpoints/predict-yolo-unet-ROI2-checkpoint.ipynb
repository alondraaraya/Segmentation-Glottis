{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7c92f2a-c23d-4d23-94b0-5962e85a3995",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow_addons as tfa\n",
    "import imageio as io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31a264e2-a8f7-4f64-8cba-9d4a2e09d7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet_mask(image, unet_model):\n",
    "    \"\"\"\n",
    "    Genera una máscara de segmentación utilizando un modelo Unet.\n",
    "\n",
    "    Parámetros:\n",
    "    image (numpy.ndarray): Imagen de entrada en formato de array numpy.\n",
    "    unet_model (Unet): Modelo Unet preentrenado.\n",
    "\n",
    "    Retorna:\n",
    "    numpy.ndarray: Máscara de segmentación binaria.\n",
    "    \"\"\"\n",
    "    if image is None or image.size == 0:\n",
    "        print(\"Warning: Empty image received in get_unet_mask.\")\n",
    "        return None\n",
    "    \n",
    "    img_orig = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # Convertir a escala de grises\n",
    "    img_orig_resized = cv2.resize(img_orig, (unet_model.input_shape[2], unet_model.input_shape[1]))  # Redimensionar\n",
    "    img_orig_resized = np.expand_dims(img_orig_resized, axis=-1)  # Añadir el canal de profundidad\n",
    "    img_orig_resized = np.expand_dims(img_orig_resized, axis=0) / 255.0  # Normalizar entre 0 y 1\n",
    "    \n",
    "    mask = unet_model.predict(img_orig_resized)\n",
    "    \n",
    "    if isinstance(mask, list):\n",
    "        mask = mask[0]\n",
    "    \n",
    "    if mask.ndim == 4:\n",
    "        mask = mask[0, :, :, 0]\n",
    "    \n",
    "    mask = (mask > 0.5).astype(np.uint8)  # Umbral para convertir en binario\n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a03a598-68e4-4e2d-adbc-a3b04e55f80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yolo_mask(image, model):\n",
    "    \"\"\"\n",
    "    Genera una máscara de segmentación utilizando un modelo YOLO.\n",
    "\n",
    "    Parámetros:\n",
    "    image (numpy.ndarray): Imagen de entrada en formato de array numpy.\n",
    "    model (YOLO): Modelo YOLO preentrenado.\n",
    "\n",
    "    Retorna:\n",
    "    numpy.ndarray: Máscara de segmentación binaria.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        original_shape = image.shape[:2]\n",
    "        results = model(image)\n",
    "\n",
    "        mask = np.zeros(original_shape, dtype=np.uint8)\n",
    "\n",
    "        if results[0].masks is not None:\n",
    "            masks = results[0].masks.xy\n",
    "            for mask_array in masks:\n",
    "                if mask_array.shape[0] == 0:  # Manejar el caso de máscaras vacías\n",
    "                    continue\n",
    "                mask_array = mask_array.astype(np.int32)\n",
    "                cv2.fillPoly(mask, [mask_array], 1)\n",
    "        else:\n",
    "            print(\"No masks found in the results\")\n",
    "\n",
    "        mask = mask.astype(bool)\n",
    "        return mask\n",
    "    except Exception as e:\n",
    "        print(f\"Error in get_yolo_mask for image {image}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbe1b0a8-ddcf-47f6-9ba6-5e89b65e172d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para encontrar contornos en la máscara y dibujarlos en la imagen original\n",
    "def draw_contours_on_image(mask, img_orig, contour_color=(0, 255, 0), contour_thickness=3):\n",
    "    contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    img_with_contours = cv2.cvtColor(img_orig, cv2.COLOR_GRAY2BGR)\n",
    "    cv2.drawContours(img_with_contours, contours, -1, contour_color, contour_thickness)\n",
    "    return img_with_contours\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "063df640-58c7-45be-9bdb-a7f6c796c68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_hybrid_video(input_video_path, yolo_model, unet_model, output_video_path):\n",
    "    ims = io.mimread(input_video_path, memtest=False)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    ancho, alto = None, None\n",
    "    output_video = None\n",
    "\n",
    "    for img_orig in ims:\n",
    "        img_orig = img_orig.astype(np.float32)\n",
    "\n",
    "        # Preprocesar para YOLO\n",
    "        yolo_mask = get_yolo_mask(img_orig, yolo_model)\n",
    "        \n",
    "        if yolo_mask is None or np.sum(yolo_mask) == 0:\n",
    "            # Si YOLO no detecta nada, usar UNet\n",
    "            unet_mask = get_unet_mask(img_orig, unet_model)\n",
    "            if unet_mask is None:\n",
    "                print(\"Warning: UNet mask is empty, skipping frame.\")\n",
    "                continue\n",
    "            x, y, w, h = cv2.boundingRect(unet_mask.astype(np.uint8))\n",
    "            if w == 0 or h == 0:\n",
    "                print(\"Warning: Empty bounding box, skipping frame.\")\n",
    "                continue\n",
    "            roi = img_orig[y:y+h, x:x+w]\n",
    "            refined_mask = get_unet_mask(roi, unet_model)\n",
    "            final_mask = np.zeros_like(img_orig[:, :, 0])\n",
    "            final_mask[y:y+h, x:x+w] = refined_mask\n",
    "        else:\n",
    "            final_mask = yolo_mask\n",
    "        \n",
    "        img_with_contours = draw_contours_on_image(final_mask, img_orig)\n",
    "        \n",
    "        if img_with_contours.dtype != np.uint8:\n",
    "            img_with_contours = img_with_contours.astype(np.uint8)\n",
    "\n",
    "        if ancho is None or alto is None:\n",
    "            alto, ancho = img_with_contours.shape[:2]\n",
    "            output_video = cv2.VideoWriter(output_video_path, fourcc, 30, (ancho, alto))\n",
    "\n",
    "        output_video.write(img_with_contours)\n",
    "\n",
    "    if output_video is not None:\n",
    "        output_video.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bd4d4cc-103c-47da-b52f-1be0e5b89547",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in get_yolo_mask for image [[[          9           1           4]\n",
      "  [          7           0           2]\n",
      "  [          1           1           1]\n",
      "  ...\n",
      "  [          4           0           1]\n",
      "  [          4           0           1]\n",
      "  [          4           0           1]]\n",
      "\n",
      " [[          8           0           3]\n",
      "  [          6           0           1]\n",
      "  [          0           0           0]\n",
      "  ...\n",
      "  [          4           0           1]\n",
      "  [          4           0           1]\n",
      "  [          4           0           1]]\n",
      "\n",
      " [[          1           0           2]\n",
      "  [          0           0           1]\n",
      "  [          0           0           0]\n",
      "  ...\n",
      "  [          0           4           1]\n",
      "  [          0           4           1]\n",
      "  [          0           4           1]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[          0           0           0]\n",
      "  [          0           0           0]\n",
      "  [          0           0           0]\n",
      "  ...\n",
      "  [          0           0           0]\n",
      "  [          0           0           0]\n",
      "  [          0           0           0]]\n",
      "\n",
      " [[          0           0           0]\n",
      "  [          0           0           0]\n",
      "  [          0           0           0]\n",
      "  ...\n",
      "  [          0           0           0]\n",
      "  [          0           0           0]\n",
      "  [          0           0           0]]\n",
      "\n",
      " [[          0           0           0]\n",
      "  [          0           0           0]\n",
      "  [          0           0           0]\n",
      "  ...\n",
      "  [          0           0           0]\n",
      "  [          0           0           0]\n",
      "  [          0           0           0]]]: CUDA out of memory. Tried to allocate 32.00 MiB. GPU \n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node model_1/conv2d_9/Conv2D defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 701, in start\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"/tmp/ipykernel_3883483/1301881982.py\", line 8, in <module>\n\n  File \"/tmp/ipykernel_3883483/971572112.py\", line 15, in process_hybrid_video\n\n  File \"/tmp/ipykernel_3883483/4292258665.py\", line 21, in get_unet_mask\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2655, in predict\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2440, in predict_function\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2425, in step_function\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2413, in run_step\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2381, in predict_step\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/keras/src/engine/training.py\", line 590, in __call__\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py\", line 290, in call\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py\", line 262, in convolution_op\n\nDNN library is not found.\n\t [[{{node model_1/conv2d_9/Conv2D}}]] [Op:__inference_predict_function_3470]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m video_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/voicelab/Desktop/segmentation_glottis/videos_VPLab/FN001.avi\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      7\u001b[0m output_video_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/voicelab/Desktop/segmentation_glottis/YOLO+UNet/videos_yolo_unet/FN001_YOLO_UNet.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 8\u001b[0m process_hybrid_video(video_path, yolo_model, unet_model, output_video_path)\n",
      "Cell \u001b[0;32mIn[5], line 15\u001b[0m, in \u001b[0;36mprocess_hybrid_video\u001b[0;34m(input_video_path, yolo_model, unet_model, output_video_path)\u001b[0m\n\u001b[1;32m     11\u001b[0m yolo_mask \u001b[38;5;241m=\u001b[39m get_yolo_mask(img_orig, yolo_model)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m yolo_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum(yolo_mask) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Si YOLO no detecta nada, usar UNet\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     unet_mask \u001b[38;5;241m=\u001b[39m get_unet_mask(img_orig, unet_model)\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m unet_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWarning: UNet mask is empty, skipping frame.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 21\u001b[0m, in \u001b[0;36mget_unet_mask\u001b[0;34m(image, unet_model)\u001b[0m\n\u001b[1;32m     18\u001b[0m img_orig_resized \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_orig_resized, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Añadir el canal de profundidad\u001b[39;00m\n\u001b[1;32m     19\u001b[0m img_orig_resized \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_orig_resized, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m  \u001b[38;5;66;03m# Normalizar entre 0 y 1\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m mask \u001b[38;5;241m=\u001b[39m unet_model\u001b[38;5;241m.\u001b[39mpredict(img_orig_resized)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mask, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     24\u001b[0m     mask \u001b[38;5;241m=\u001b[39m mask[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/tmpenv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/tmpenv/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node model_1/conv2d_9/Conv2D defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 701, in start\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"/tmp/ipykernel_3883483/1301881982.py\", line 8, in <module>\n\n  File \"/tmp/ipykernel_3883483/971572112.py\", line 15, in process_hybrid_video\n\n  File \"/tmp/ipykernel_3883483/4292258665.py\", line 21, in get_unet_mask\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2655, in predict\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2440, in predict_function\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2425, in step_function\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2413, in run_step\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2381, in predict_step\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/keras/src/engine/training.py\", line 590, in __call__\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py\", line 290, in call\n\n  File \"/home/voicelab/miniconda3/envs/tmpenv/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py\", line 262, in convolution_op\n\nDNN library is not found.\n\t [[{{node model_1/conv2d_9/Conv2D}}]] [Op:__inference_predict_function_3470]"
     ]
    }
   ],
   "source": [
    "yolo_model_path = \"/home/voicelab/Desktop/segmentation_glottis/YOLOv8_medium/runs/segment/train/weights/best.pt\"\n",
    "yolo_model = YOLO(yolo_model_path)\n",
    "unet_model_path = \"/home/voicelab/Downloads/epoch025.h5\"\n",
    "unet_model = load_model(unet_model_path, compile=False, custom_objects={'InstanceNormalization': tfa.layers.InstanceNormalization})\n",
    "\n",
    "video_path = '/home/voicelab/Desktop/segmentation_glottis/videos_VPLab/FN001.avi'\n",
    "output_video_path = '/home/voicelab/Desktop/segmentation_glottis/YOLO+UNet/videos_yolo_unet/FN001_YOLO_UNet.mp4'\n",
    "process_hybrid_video(video_path, yolo_model, unet_model, output_video_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b43cd5b-29dc-427a-8543-79d7f4eca787",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

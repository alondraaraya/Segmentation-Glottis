{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"pgjVc_W44C4s"},"outputs":[],"source":["!pip install tensorflow numpy pandas tqdm scikit-learn segmentation-models tensorflow-addons flammkuchen opencv-python-headless imageio"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23434,"status":"ok","timestamp":1700866283161,"user":{"displayName":"Voice Production Laboratory","userId":"06343012582981241924"},"user_tz":180},"id":"sjtnqAXTWj5W","outputId":"c8877cb7-ec44-46dd-cecc-6765c5de900a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5766,"status":"ok","timestamp":1700867450076,"user":{"displayName":"Voice Production Laboratory","userId":"06343012582981241924"},"user_tz":180},"id":"uTI4ymrq4Q9T","outputId":"0c3d3a5f-3c39-4b88-b1ea-faedffd3e41d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Segmentation Models: using `tf.keras` framework.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n","\n","TensorFlow Addons (TFA) has ended development and introduction of new features.\n","TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n","Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n","\n","For more information see: https://github.com/tensorflow/addons/issues/2807 \n","\n","  warnings.warn(\n"]}],"source":["import os\n","import tensorflow as tf\n","os.environ['SM_FRAMEWORK'] = 'tf.keras'\n","import numpy as np\n","import pandas as pd\n","import random\n","from tqdm.notebook import tqdm\n","\n","from sklearn.model_selection import train_test_split\n","from segmentation_models.losses import dice_loss\n","from segmentation_models.metrics import iou_score\n","\n","#from drive.MyDrive.Glottis.colab_glottis.GlottisNetV2.Utils.data import load_data, MAPE_V1, mape_apV1, mape_ppV1\n","from drive.MyDrive.Glottis.colab_glottis.GlottisNetV2.Utils.data import load_data, metric_mape, mape_ap, mape_pp\n","from drive.MyDrive.Glottis.colab_glottis.GlottisNetV2.Utils.Callbacks import get_callbacks\n","from drive.MyDrive.Glottis.colab_glottis.GlottisNetV2.Models.GlottisNetV2_e import glottisnetV2_e\n","\n","\n","import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OBpIjziP4bbZ","outputId":"de4cb393-1ebb-48f2-c7e5-45aeb59c1398","executionInfo":{"status":"ok","timestamp":1700867497120,"user_tz":180,"elapsed":17260,"user":{"displayName":"Voice Production Laboratory","userId":"06343012582981241924"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 1s/step\n","1/1 [==============================] - 0s 342ms/step\n","1/1 [==============================] - 0s 328ms/step\n","1/1 [==============================] - 0s 321ms/step\n","1/1 [==============================] - 0s 334ms/step\n","1/1 [==============================] - 0s 304ms/step\n","1/1 [==============================] - 0s 300ms/step\n","1/1 [==============================] - 0s 292ms/step\n","1/1 [==============================] - 0s 297ms/step\n","1/1 [==============================] - 0s 335ms/step\n","1/1 [==============================] - 0s 310ms/step\n","1/1 [==============================] - 0s 306ms/step\n","1/1 [==============================] - 0s 321ms/step\n","1/1 [==============================] - 0s 327ms/step\n","1/1 [==============================] - 0s 315ms/step\n","1/1 [==============================] - 0s 342ms/step\n","1/1 [==============================] - 0s 320ms/step\n","1/1 [==============================] - 0s 331ms/step\n","1/1 [==============================] - 0s 306ms/step\n","1/1 [==============================] - 0s 386ms/step\n","1/1 [==============================] - 0s 416ms/step\n","1/1 [==============================] - 0s 436ms/step\n","1/1 [==============================] - 0s 471ms/step\n","1/1 [==============================] - 0s 437ms/step\n","1/1 [==============================] - 0s 487ms/step\n","1/1 [==============================] - 0s 484ms/step\n","1/1 [==============================] - 0s 460ms/step\n","1/1 [==============================] - 0s 415ms/step\n","1/1 [==============================] - 0s 381ms/step\n","1/1 [==============================] - 0s 307ms/step\n"]}],"source":["import flammkuchen as fl\n","import cv2\n","import os\n","from tqdm.notebook import tqdm\n","import imageio as io\n","from tensorflow.keras.models import load_model\n","os.environ['SM_FRAMEWORK'] = 'tf.keras'\n","import tensorflow_addons as tfa\n","from drive.MyDrive.Glottis.colab_glottis.GlottisNetV2.Utils.data import load_data\n","\n","# Iterate through videos\n","for vi in range(0, 1):\n","\n","    # Set path of current video\n","    #vpath = r\"drive/MyDrive/Glottis/videos/videos/\" + str(vi) + \".mp4\" # TODO: Set path\n","    vpath = r\"drive/MyDrive/Glottis/videos_BAGLS/40.mp4\" # TODO: Set path\n","    if os.path.exists(vpath):\n","        # Set model path\n","        path_model = r\"drive/MyDrive/Glottis/GlottisNetV2e/models/steps/epoch025.h5\" # TODO: Set path\n","\n","        # Load frames fo video\n","        ims = io.mimread(vpath, memtest=False)\n","\n","        # Load model\n","        Unet = load_model(path_model, compile=False,\n","                          custom_objects={'InstanceNormalization': tfa.layers.InstanceNormalization})\n","\n","        # Initialize lists to hold data\n","        masks = []\n","        ims_orig = []\n","\n","        # Iterate through frames\n","        for i in range(len(ims)):\n","\n","            # Preprocess image for prediction\n","            img_orig = ims[i].astype(np.float32)\n","\n","            # Color --> gray and normalize image\n","            img_orig = cv2.cvtColor(img_orig, cv2.COLOR_BGR2GRAY)\n","            img = cv2.resize(img_orig, (256, 512))\n","\n","            # Normalize and preprocess image\n","            normalizedImg = np.zeros(img.shape)\n","            img = cv2.normalize(img, normalizedImg, -1, 1, cv2.NORM_MINMAX)\n","            img = img[None, ..., None]\n","\n","            # Prediction\n","            pred_maps, seg_pred = Unet.predict(img)\n","            mask = np.asarray(np.squeeze(seg_pred))\n","\n","            # Convert probabilities to boolean\n","            mask = np.round(mask)\n","\n","            # Resize, convert and transpose mask to get the right shape [frames, x, y] (type: boolean)\n","            mask = cv2.resize(mask, (img_orig.shape[1], img_orig.shape[0]))\n","            mask = mask.astype(bool)\n","            mask = np.transpose(mask, (1, 0))\n","            img_orig = np.transpose(img_orig, (1, 0))\n","\n","            # Append images to lists\n","            masks.append(mask)\n","            ims_orig.append(img_orig)\n","\n","        # Convert list to numpy array\n","        masks = np.asarray(masks)\n","\n","        # Save sequence of masks as .mask file\n","        #path1 = r\"drive/MyDrive/Glottis/masks/\" + str(vi) + \".mask\" # TODO: Set path\n","        path1 = r\"drive/MyDrive/Glottis/GlottisNetV2e/Masks/40.mask\" # TODO: Set path\n","\n","        fl.save(path1, {\"mask\": masks, 'files': ims_orig}, compression='blosc')\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1hT_kHnh-85Sa9O53oz0f7nHGOo7q6X59"},"executionInfo":{"elapsed":3278,"status":"ok","timestamp":1700867532356,"user":{"displayName":"Voice Production Laboratory","userId":"06343012582981241924"},"user_tz":180},"id":"sYdDaKrB4ply","outputId":"6c6e5c72-8758-45e9-88d6-fac6d432a87e"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["from google.colab.patches import cv2_imshow\n","\n","# Ruta al archivo .mask que deseas visualizar\n","mask_file_path = \"drive/MyDrive/Glottis/GlottisNetV2e/Masks/40.mask\"  # Asegúrate de ajustar la ruta según tu ubicación\n","\n","# Cargar el archivo .mask\n","data = fl.load(mask_file_path)\n","\n","# Obtener las máscaras y las imágenes originales\n","masks = data[\"mask\"]\n","images = data[\"files\"]\n","\n","# Iterar a través de las máscaras y mostrarlas junto con las imágenes originales\n","for i in range(len(masks)):\n","    # Escala la máscara para que sea más visible (puedes ajustar la escala según tus necesidades)\n","    scaled_mask = (masks[i] * 255).astype(np.uint8)\n","\n","    # Muestra la imagen original y la máscara utilizando cv2_imshow\n","    cv2_imshow(images[i])\n","    cv2_imshow(scaled_mask)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"16afCRO2hIf_d5ri3uK5aVKqGuxQBbMrY"},"executionInfo":{"elapsed":2598,"status":"ok","timestamp":1700867606651,"user":{"displayName":"Voice Production Laboratory","userId":"06343012582981241924"},"user_tz":180},"id":"QcLiliwel7y7","outputId":"8b6dc052-664c-4bde-cf87-cfc0dc4d4fdd"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["from google.colab.patches import cv2_imshow\n","import flammkuchen as fl\n","import cv2\n","import numpy as np\n","\n","# Esta función encuentra contornos en la máscara y dibuja los contornos en la imagen original\n","def draw_contours_on_image(mask, img_orig, contour_color=(255, 255, 255)):\n","    # Find contours in the mask\n","    contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","\n","    # Create a copy of the original image\n","    img_with_contours = img_orig.copy()\n","\n","    # Draw the contours on the original image using the specified contour_color\n","    cv2.drawContours(img_with_contours, contours, -1, contour_color, 2)\n","\n","    return img_with_contours\n","\n","\n","# Configurar los parámetros del video\n","fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Puedes ajustar el códec según tus preferencias\n","# Inicializar las dimensiones de ancho y alto\n","ancho, alto = None, None\n","\n","# Crear el objeto de video sin dimensiones (se configurarán más tarde)\n","output_video = None\n","\n","for i in range(len(masks)):\n","    # Llama a la función para dibujar contornos\n","    img_with_contours = draw_contours_on_image(masks[i], images[i])\n","\n","    # Convertir la imagen a 8 bits sin signo si no lo está ya\n","    if img_with_contours.dtype != np.uint8:\n","        img_with_contours = img_with_contours.astype(np.uint8)\n","\n","    # Verificar si las dimensiones del video se han configurado\n","    if ancho is None or alto is None:\n","        alto, ancho = img_with_contours.shape[:2]\n","        # Crear el objeto de video con las dimensiones de la imagen\n","        output_video = cv2.VideoWriter('output_video.mp4', fourcc, 30, (ancho, alto))\n","\n","    # Agregar la imagen con contornos al video\n","    output_video.write(img_with_contours)\n","\n","    # Mostrar la imagen con los contornos utilizando cv2_imshow\n","    cv2_imshow(img_with_contours)\n","\n","output_video.release()\n","\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
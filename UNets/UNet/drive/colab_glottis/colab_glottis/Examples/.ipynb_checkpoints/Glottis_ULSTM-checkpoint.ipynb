{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bae979a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pillow numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16e46c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
    "from tensorflow.keras.layers import TimeDistributed, Bidirectional, LSTM, ConvLSTM2D\n",
    "\n",
    "def conv_block(input_tensor, num_filters):\n",
    "    x = TimeDistributed(Conv2D(num_filters, (3, 3), padding='same', activation='relu'))(input_tensor)\n",
    "    x = TimeDistributed(Conv2D(num_filters, (3, 3), padding='same', activation='relu'))(x)\n",
    "    return x\n",
    "\n",
    "def conv_lstm_block(input_tensor, num_filters):\n",
    "    x = Bidirectional(ConvLSTM2D(num_filters, (3, 3), padding='same', return_sequences=True))(input_tensor)\n",
    "    return x\n",
    "\n",
    "def unet_lstm(input_size=(256, 256, 3), n_sequences=10, n_filters=64, n_classes=4):\n",
    "    inputs = Input((n_sequences, *input_size))\n",
    "\n",
    "    # Downsample\n",
    "    c1 = conv_block(inputs, n_filters)\n",
    "    l1 = conv_lstm_block(c1, n_filters)\n",
    "    p1 = TimeDistributed(MaxPooling2D((2, 2)))(l1)\n",
    "\n",
    "    c2 = conv_block(p1, n_filters*2)\n",
    "    l2 = conv_lstm_block(c2, n_filters*2)\n",
    "    p2 = TimeDistributed(MaxPooling2D((2, 2)))(l2)\n",
    "\n",
    "    # Bottleneck\n",
    "    c3 = conv_block(p2, n_filters*4)\n",
    "\n",
    "    # Upsample\n",
    "    u1 = TimeDistributed(UpSampling2D((2, 2)))(c3)\n",
    "    concat1 = concatenate([u1, l2], axis=4)\n",
    "    c4 = conv_block(concat1, n_filters*2)\n",
    "\n",
    "    u2 = TimeDistributed(UpSampling2D((2, 2)))(c4)\n",
    "    concat2 = concatenate([u2, l1], axis=4)\n",
    "    c5 = conv_block(concat2, n_filters)\n",
    "\n",
    "    # Output layer\n",
    "    outputs = TimeDistributed(Conv2D(n_classes, (1, 1), activation='softmax'))(c5)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "model = unet_lstm()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aab4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import shuffle\n",
    "import logging\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "\n",
    "from random import shuffle\n",
    "from glob import glob\n",
    "\n",
    "class SequenceDataProvider:\n",
    "    def __init__(self, data_dir, sequence_length, image_suffix, label_suffix, input_size, n_classes, shuffle_data=True, max_sequences=None):\n",
    "        self._data_dir = data_dir\n",
    "        self._sequence_length = sequence_length\n",
    "        self._image_suffix = image_suffix\n",
    "        self._label_suffix = label_suffix\n",
    "        self._input_size = input_size\n",
    "        self._n_classes = n_classes\n",
    "        self._shuffle_data = shuffle_data\n",
    "        self._max_sequences = max_sequences\n",
    "        self._sequences = self._load_sequences()\n",
    "\n",
    "    def dataset_length(self):\n",
    "        # Devuelve el número total de secuencias cargadas\n",
    "        return len(self._sequences)\n",
    "\n",
    "    def _load_sequences(self):\n",
    "        image_paths = sorted(glob(f\"{self._data_dir}/*{self._image_suffix}\"))\n",
    "        label_paths = sorted(glob(f\"{self._data_dir}/*{self._label_suffix}\"))\n",
    "\n",
    "        sequences = [\n",
    "            list(zip(image_paths[i:i+self._sequence_length], label_paths[i:i+self._sequence_length]))\n",
    "            for i in range(0, len(image_paths) - self._sequence_length + 1, self._sequence_length)\n",
    "        ]\n",
    "\n",
    "        if self._max_sequences:\n",
    "            sequences = sequences[:self._max_sequences]\n",
    "\n",
    "        if self._shuffle_data:\n",
    "            shuffle(sequences)\n",
    "        print(f\"Loaded {len(sequences)} sequences.\")\n",
    "        return sequences\n",
    "\n",
    "    def _process_image(self, image_path):\n",
    "        image = Image.open(image_path)\n",
    "        image = image.resize(self._input_size[:2])  # Assuming input_size is (height, width, channels)\n",
    "        return np.array(image)\n",
    "\n",
    "    def _process_label(self, label_path):\n",
    "        label = Image.open(label_path)\n",
    "        label = label.resize(self._input_size[:2])\n",
    "        label = np.array(label, dtype=np.int32)  # Asegúrate de que sea entero para usar como índices\n",
    "\n",
    "        # Convertir la etiqueta a formato one-hot\n",
    "        one_hot_label = np.eye(self._n_classes)[label]\n",
    "        return one_hot_label\n",
    "\n",
    "    def next_batch(self, batch_size=1):\n",
    "        batch_images = []\n",
    "        batch_labels = []\n",
    "        for _ in range(batch_size):\n",
    "            if len(self._sequences) == 0:\n",
    "                self._sequences = self._load_sequences()\n",
    "\n",
    "            sequence = self._sequences.pop(0)\n",
    "            sequence_images = []\n",
    "            sequence_labels = []\n",
    "\n",
    "            for image_path, label_path in sequence:\n",
    "                image = self._process_image(image_path)\n",
    "                label = self._process_label(label_path)\n",
    "                sequence_images.append(image)\n",
    "                sequence_labels.append(label)\n",
    "\n",
    "            batch_images.append(sequence_images)\n",
    "            batch_labels.append(sequence_labels)\n",
    "        print(np.array(batch_labels).shape)\n",
    "\n",
    "        batch_images = np.array(batch_images).reshape(batch_size, self._sequence_length, *self._input_size)\n",
    "        # Asegúrate de ajustar el reshape de batch_labels para que coincida con las dimensiones esperadas por tu modelo\n",
    "        batch_labels = np.array(batch_labels).reshape(batch_size, self._sequence_length, *self._input_size[:2], self._n_classes)\n",
    "\n",
    "        return batch_images, batch_labels\n",
    "\n",
    "# Asegúrate de definir input_size y n_classes acorde a tu modelo\n",
    "input_size = (256, 256, 3)  # Ejemplo de tamaño de entrada\n",
    "n_classes = 4  # Ejemplo de número de clases\n",
    "\n",
    "data_provider = SequenceDataProvider(\n",
    "    data_dir=\"/content/drive/MyDrive/Glottis/dataset/dataset/train\",\n",
    "    sequence_length=10,\n",
    "    image_suffix=\"_rgb.png\",\n",
    "    label_suffix=\"_mask.png\",\n",
    "    input_size=(256, 256, 3),\n",
    "    n_classes=4,\n",
    "    shuffle_data=True,\n",
    "    max_sequences=10\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91187f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10  # Número de épocas para el entrenamiento\n",
    "batch_size = 2  # Tamaño del lote\n",
    "def data_generator(batch_size):\n",
    "    while True:\n",
    "        batch_images, batch_labels = data_provider.next_batch(batch_size)\n",
    "        yield batch_images, batch_labels\n",
    "\n",
    "# Crear el generador\n",
    "train_generator = data_generator(batch_size)\n",
    "\n",
    "# Calcular el número de pasos por época\n",
    "steps_per_epoch = data_provider.dataset_length() // batch_size\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(x=train_generator,\n",
    "          steps_per_epoch=steps_per_epoch,\n",
    "          epochs=epochs)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

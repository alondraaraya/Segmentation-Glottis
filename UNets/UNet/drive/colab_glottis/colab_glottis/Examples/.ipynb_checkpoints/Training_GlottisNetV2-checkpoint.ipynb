{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46a85878",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " #!pip install numpy pandas tqdm scikit-learn segmentation-models tensorflow-addons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5a6a1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install albumentations --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f29722f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.1\n",
      "GPU Available:  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-24 22:50:53.004945: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-24 22:50:53.005309: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-24 22:50:53.005482: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-24 22:50:53.005742: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-24 22:50:53.005941: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-24 22:50:53.006084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 550 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4080 SUPER, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2024-09-24 22:51:03.007272: W external/local_tsl/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 381.47MiB (rounded to 400000000)requested by op RandomStandardNormal\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2024-09-24 22:51:03.007332: I external/local_tsl/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for GPU_0_bfc\n",
      "2024-09-24 22:51:03.007364: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 2, Chunks in use: 2. 512B allocated for chunks. 512B in use in bin. 8B client-requested in use in bin.\n",
      "2024-09-24 22:51:03.007378: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-09-24 22:51:03.007397: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2024-09-24 22:51:03.007412: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-09-24 22:51:03.007424: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-09-24 22:51:03.007436: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-09-24 22:51:03.007447: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-09-24 22:51:03.007460: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-09-24 22:51:03.007471: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-09-24 22:51:03.007483: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-09-24 22:51:03.007495: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-09-24 22:51:03.007507: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-09-24 22:51:03.007519: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-09-24 22:51:03.007532: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-09-24 22:51:03.007544: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-09-24 22:51:03.007556: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-09-24 22:51:03.007569: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-09-24 22:51:03.007582: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-09-24 22:51:03.007593: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-09-24 22:51:03.007609: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 1, Chunks in use: 0. 168.84MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-09-24 22:51:03.007625: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 1, Chunks in use: 1. 381.47MiB allocated for chunks. 381.47MiB in use in bin. 381.47MiB client-requested in use in bin.\n",
      "2024-09-24 22:51:03.007665: I external/local_tsl/tsl/framework/bfc_allocator.cc:1062] Bin for 381.47MiB was 256.00MiB, Chunk State: \n",
      "2024-09-24 22:51:03.007680: I external/local_tsl/tsl/framework/bfc_allocator.cc:1075] Next region of size 577044480\n",
      "2024-09-24 22:51:03.007695: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 772bd6000000 of size 1280 next 1\n",
      "2024-09-24 22:51:03.007706: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 772bd6000500 of size 256 next 2\n",
      "2024-09-24 22:51:03.007896: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 772bd6000600 of size 256 next 3\n",
      "2024-09-24 22:51:03.007937: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 772bd6000700 of size 400000000 next 4\n",
      "2024-09-24 22:51:03.007960: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 772bedd78b00 of size 177042688 next 18446744073709551615\n",
      "2024-09-24 22:51:03.007981: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
      "2024-09-24 22:51:03.008002: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 256 totalling 512B\n",
      "2024-09-24 22:51:03.008027: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2024-09-24 22:51:03.008049: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 400000000 totalling 381.47MiB\n",
      "2024-09-24 22:51:03.008070: I external/local_tsl/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 381.47MiB\n",
      "2024-09-24 22:51:03.008089: I external/local_tsl/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 577044480 memory_limit_: 577044480 available bytes: 0 curr_region_allocation_bytes_: 1154088960\n",
      "2024-09-24 22:51:03.008114: I external/local_tsl/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
      "Limit:                       577044480\n",
      "InUse:                       400001792\n",
      "MaxInUse:                    400001792\n",
      "NumAllocs:                           4\n",
      "MaxAllocSize:                400000000\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2024-09-24 22:51:03.008138: W external/local_tsl/tsl/framework/bfc_allocator.cc:497] **********************************************************************______________________________\n",
      "2024-09-24 22:51:03.008192: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at random_op.cc:74 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[10000,10000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped__RandomStandardNormal_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[10000,10000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:RandomStandardNormal] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Forzar una operación para comprobar el uso de la GPU\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/GPU:0\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m----> 9\u001b[0m     a \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal([\u001b[38;5;241m10000\u001b[39m, \u001b[38;5;241m10000\u001b[39m])\n\u001b[1;32m     10\u001b[0m     b \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal([\u001b[38;5;241m10000\u001b[39m, \u001b[38;5;241m10000\u001b[39m])\n\u001b[1;32m     11\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/miniconda3/envs/tmpenv/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/tmpenv/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:5883\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5881\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m   5882\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 5883\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__RandomStandardNormal_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[10000,10000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:RandomStandardNormal] name: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "print(tf.__version__)\n",
    "print('GPU Available: ', tf.test.is_gpu_available())\n",
    "\n",
    "\n",
    "# Forzar una operación para comprobar el uso de la GPU\n",
    "with tf.device('/GPU:0'):\n",
    "    a = tf.random.normal([10000, 10000])\n",
    "    b = tf.random.normal([10000, 10000])\n",
    "    start_time = time.time()\n",
    "    c = tf.matmul(a, b)\n",
    "    end_time = time.time()\n",
    "    print('GPU Available: ', tf.test.is_gpu_available())\n",
    "\n",
    "\n",
    "print(f\"Tiempo de ejecución en la GPU: {end_time - start_time} segundos\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91af4172",
   "metadata": {
    "id": "91af4172"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "os.environ['SM_FRAMEWORK'] = 'tf.keras'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from segmentation_models.losses import dice_loss\n",
    "from segmentation_models.metrics import iou_score\n",
    "\n",
    "module_path = \"/home/voicelab/Desktop/segmentation_glottis/UNet/drive/colab_glottis/colab_glottis/GlottisNetV2\"\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "#Drive\n",
    "#from drive.MyDrive.Glottis.colab_glottis.GlottisNetV2.Utils.DataGenerator import DataGenerator\n",
    "#from drive.MyDrive.Glottis.colab_glottis.GlottisNetV2.Utils.data import load_data, metric_mape, mape_ap, mape_pp\n",
    "#from drive.MyDrive.Glottis.colab_glottis.GlottisNetV2.Utils.Callbacks import get_callbacks\n",
    "#from drive.MyDrive.Glottis.colab_glottis.GlottisNetV2.Models.GlottisNetV2_e import glottisnetV2_e\n",
    "\n",
    "from Models.GlottisNetV2_e import glottisnetV2_e\n",
    "from Utils.DataGenerator_onlySeg import DataGenerator\n",
    "from Utils.data import load_data, metric_mape, mape_ap, mape_pp\n",
    "from Utils.Callbacks import get_callbacks\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16061812",
   "metadata": {
    "id": "16061812",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def is_image_valid(image_path):\n",
    "    return os.path.getsize(image_path) > 0\n",
    "\n",
    "img_training = \"/home/voicelab/Desktop/segmentation_glottis/BAGLS_ROI/training\" # TODO\n",
    "\n",
    "N_train = 55750\n",
    "\n",
    "cols = ['z', 'path']\n",
    "df_imgs_train = pd.DataFrame(columns=cols)\n",
    "df_segs_train = pd.DataFrame(columns=cols)\n",
    "\n",
    "for i in tqdm(range(0, N_train )):  # Asegúrate de que el rango esté correctamente definido\n",
    "    rgb_path = os.path.join(img_training, f\"{i}.png\")\n",
    "    mask_path = os.path.join(img_training, f\"{i}_seg.png\")\n",
    "\n",
    "    # Solo agrega las rutas si tanto la imagen como la máscara son válidas\n",
    "    if os.path.exists(rgb_path) and os.path.exists(mask_path) and is_image_valid(rgb_path) and is_image_valid(mask_path):\n",
    "        row_imgs = {'z': [i], 'path': [rgb_path]}\n",
    "        row_segs = {'z': [i], 'path': [mask_path]}\n",
    "\n",
    "        df_imgs_train = pd.concat([df_imgs_train, pd.DataFrame(row_imgs)])\n",
    "        df_segs_train = pd.concat([df_segs_train, pd.DataFrame(row_segs)])\n",
    "    else:\n",
    "        print(f\"Omitiendo debido a imagen/máscara inválida o inexistente: {rgb_path}, {mask_path}\")\n",
    "\n",
    "print(df_imgs_train.tail())\n",
    "print(df_segs_train.tail())\n",
    "\n",
    "print('Created IDs for training images.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954d126d",
   "metadata": {
    "id": "954d126d"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "'''Training'''\n",
    "# Set random seed for reproducible training\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "rand=np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "tf.compat.v1.set_random_seed(SEED)\n",
    "\n",
    "# Set parameters\n",
    "BATCH_SIZE = 8\n",
    "FILTERS = 16\n",
    "LAYERS= 4\n",
    "LEARNING_RATE = 0.2e-3\n",
    "EPOCHS = 30\n",
    "TARGET_HEIGHT = 128\n",
    "TARGET_WIDTH = 256\n",
    "SHUFFLE = True\n",
    "AUGMENT = False\n",
    "MODEL_PATH = r\"/home/voicelab/Desktop/segmentation_glottis/UNet/model/model128.h5\" #TODO\n",
    "STEPS_PATH = r\"/home/voicelab/Desktop/segmentation_glottis/UNet/model/steps128\" #TODO\n",
    "N_STEPS = 5 # Save every #N_STEPS epoch\n",
    "RADIUS = 15\n",
    "\n",
    "model = glottisnetV2_e(input_size=(TARGET_HEIGHT, TARGET_WIDTH, 1), layers=LAYERS, filters=FILTERS)\n",
    "\n",
    "# Hard split of training and validation data\n",
    "train_imgs, val_imgs, train_segs, val_segs = train_test_split(df_imgs_train,\n",
    "                                                              df_segs_train,\n",
    "                                                              test_size = 0.1,\n",
    "                                                              random_state = SEED)\n",
    "\n",
    "\n",
    "# Training data --> Augmentation and Shuffle\n",
    "#training_generator = DataGenerator(train_imgs, train_segs, batch_size = BATCH_SIZE, target_height = TARGET_HEIGHT, \\\n",
    "                                   #target_width = TARGET_WIDTH, shuffle = SHUFFLE, df_coordinates = training_data, \\\n",
    "                                   #augment = AUGMENT, radius=RADIUS)\n",
    "training_generator = DataGenerator(train_imgs, train_segs, batch_size = BATCH_SIZE, target_height = TARGET_HEIGHT, \\\n",
    "                                   target_width = TARGET_WIDTH, shuffle = SHUFFLE, augment = AUGMENT, radius=RADIUS)\n",
    "# Validation data\n",
    "validation_generator = DataGenerator(val_imgs, val_segs, target_height = TARGET_HEIGHT, \\\n",
    "                                     target_width = TARGET_WIDTH, batch_size = BATCH_SIZE, shuffle = False, \\\n",
    "                                    augment = False, radius=RADIUS)\n",
    "#validation_generator = DataGenerator(val_imgs, val_segs, target_height = TARGET_HEIGHT, \\\n",
    "                                     #target_width = TARGET_WIDTH, batch_size = BATCH_SIZE, shuffle = False, \\\n",
    "                                     #df_coordinates = training_data, augment = False, radius=RADIUS)\n",
    "# Compile model with dice_loss for segmentation, mse for prediction maps and use Adam as optimizer\n",
    "# First exit: predictions of anterior and posterior points (2 channels)\n",
    "# Second exit: Segmentations\n",
    "\n",
    "for layer in model.layers:\n",
    "    if 'decode_ap' in layer.name or 'ap.pred' in layer.name:\n",
    "        layer.trainable = False\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "              metrics={'seg': ['acc', iou_score]},\n",
    "              loss={'seg': dice_loss})\n",
    "\n",
    "\n",
    "# Train model on dataset and save it\n",
    "model.fit(training_generator, validation_data= validation_generator, epochs = EPOCHS,\n",
    "                    callbacks = get_callbacks(MODEL_PATH, model, N_STEPS, STEPS_PATH))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf099a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "interpreter": {
   "hash": "ab9ad1b762d22614dfe02aceadf5b4c0b83e595e73a1a2b3522cafd6b3a0cf39"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 276,
     "status": "ok",
     "timestamp": 1700942375448,
     "user": {
      "displayName": "Voice Production Laboratory",
      "userId": "06343012582981241924"
     },
     "user_tz": 180
    },
    "id": "pgjVc_W44C4s",
    "outputId": "625b8863-f021-4126-f85e-2e396ab4ead7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: typeguard, tensorflow-addons, keras-applications, image-classifiers, flammkuchen, efficientnet, segmentation-models\n",
      "Successfully installed efficientnet-1.0.0 flammkuchen-1.0.3 image-classifiers-1.0.0 keras-applications-1.0.8 segmentation-models-1.0.1 tensorflow-addons-0.22.0 typeguard-2.13.3\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow numpy pandas tqdm scikit-learn segmentation-models tensorflow-addons flammkuchen opencv-python-headless imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17380,
     "status": "ok",
     "timestamp": 1700942392822,
     "user": {
      "displayName": "Voice Production Laboratory",
      "userId": "06343012582981241924"
     },
     "user_tz": 180
    },
    "id": "sjtnqAXTWj5W",
    "outputId": "b80af64e-d38b-4ad7-db15-e81a65dd5e31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5877,
     "status": "ok",
     "timestamp": 1700942398691,
     "user": {
      "displayName": "Voice Production Laboratory",
      "userId": "06343012582981241924"
     },
     "user_tz": 180
    },
    "id": "uTI4ymrq4Q9T",
    "outputId": "b1881a08-7490-4b3c-dd8b-10ebe20a98e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `tf.keras` framework.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ['SM_FRAMEWORK'] = 'tf.keras'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from segmentation_models.losses import dice_loss\n",
    "from segmentation_models.metrics import iou_score\n",
    "\n",
    "from drive.MyDrive.Glottis.colab_glottis.GlottisNetV2.Utils.data import load_data, MAPE_V1, mape_apV1, mape_ppV1\n",
    "#from drive.MyDrive.Glottis.colab_glottis.GlottisNetV2.Utils.data import load_data, metric_mape, mape_ap, mape_pp\n",
    "from drive.MyDrive.Glottis.colab_glottis.GlottisNetV2.Utils.Callbacks import get_callbacks\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15938,
     "status": "ok",
     "timestamp": 1700942435980,
     "user": {
      "displayName": "Voice Production Laboratory",
      "userId": "06343012582981241924"
     },
     "user_tz": 180
    },
    "id": "OBpIjziP4bbZ",
    "outputId": "1426cb53-c521-4aa2-bada-35f371b59ff0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 289ms/step\n",
      "1/1 [==============================] - 0s 294ms/step\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 286ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 293ms/step\n",
      "1/1 [==============================] - 0s 318ms/step\n",
      "1/1 [==============================] - 0s 424ms/step\n",
      "1/1 [==============================] - 0s 417ms/step\n",
      "1/1 [==============================] - 0s 439ms/step\n",
      "1/1 [==============================] - 0s 424ms/step\n",
      "1/1 [==============================] - 0s 407ms/step\n",
      "1/1 [==============================] - 0s 445ms/step\n",
      "1/1 [==============================] - 0s 405ms/step\n",
      "1/1 [==============================] - 0s 436ms/step\n",
      "1/1 [==============================] - 0s 406ms/step\n",
      "1/1 [==============================] - 0s 426ms/step\n",
      "1/1 [==============================] - 0s 295ms/step\n",
      "1/1 [==============================] - 0s 295ms/step\n",
      "1/1 [==============================] - 0s 295ms/step\n",
      "1/1 [==============================] - 0s 287ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 289ms/step\n",
      "1/1 [==============================] - 0s 313ms/step\n"
     ]
    }
   ],
   "source": [
    "import flammkuchen as fl\n",
    "import cv2\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import imageio as io\n",
    "from tensorflow.keras.models import load_model\n",
    "os.environ['SM_FRAMEWORK'] = 'tf.keras'\n",
    "import tensorflow_addons as tfa\n",
    "from drive.MyDrive.Glottis.colab_glottis.GlottisNetV2.Utils.data import load_data\n",
    "\n",
    "# Iterate through videos\n",
    "for vi in range(0, 1):\n",
    "\n",
    "    # Set path of current video\n",
    "    #vpath = r\"drive/MyDrive/Glottis/videos/videos/\" + str(vi) + \".mp4\" # TODO: Set path\n",
    "    vpath = r\"drive/MyDrive/Glottis/videos_BAGLS/40.mp4\" # TODO: Set path\n",
    "    if os.path.exists(vpath):\n",
    "        # Set model path\n",
    "        path_model = r\"drive/MyDrive/Glottis/GlottisNetV1/Model/steps/steps/epoch000.h5\" # TODO: Set path\n",
    "\n",
    "        # Load frames fo video\n",
    "        ims = io.mimread(vpath, memtest=False)\n",
    "\n",
    "        # Load model\n",
    "        Unet = load_model(path_model, compile=False,\n",
    "                          custom_objects={'InstanceNormalization': tfa.layers.InstanceNormalization})\n",
    "\n",
    "        # Initialize lists to hold data\n",
    "        masks = []\n",
    "        ims_orig = []\n",
    "\n",
    "        # Iterate through frames\n",
    "        for i in range(len(ims)):\n",
    "\n",
    "            # Preprocess image for prediction\n",
    "            img_orig = ims[i].astype(np.float32)\n",
    "\n",
    "            # Color --> gray and normalize image\n",
    "            img_orig = cv2.cvtColor(img_orig, cv2.COLOR_BGR2GRAY)\n",
    "            img = cv2.resize(img_orig, (256, 512))\n",
    "\n",
    "            # Normalize and preprocess image\n",
    "            normalizedImg = np.zeros(img.shape)\n",
    "            img = cv2.normalize(img, normalizedImg, -1, 1, cv2.NORM_MINMAX)\n",
    "            img = img[None, ..., None]\n",
    "\n",
    "            # Prediction\n",
    "            pred_maps, seg_pred = Unet.predict(img)\n",
    "            mask = np.asarray(np.squeeze(seg_pred))\n",
    "\n",
    "            # Convert probabilities to boolean\n",
    "            mask = np.round(mask)\n",
    "\n",
    "            # Resize, convert and transpose mask to get the right shape [frames, x, y] (type: boolean)\n",
    "            mask = cv2.resize(mask, (img_orig.shape[1], img_orig.shape[0]))\n",
    "            mask = mask.astype(bool)\n",
    "            mask = np.transpose(mask, (1, 0))\n",
    "            img_orig = np.transpose(img_orig, (1, 0))\n",
    "\n",
    "            # Append images to lists\n",
    "            masks.append(mask)\n",
    "            ims_orig.append(img_orig)\n",
    "\n",
    "        # Convert list to numpy array\n",
    "        masks = np.asarray(masks)\n",
    "\n",
    "        # Save sequence of masks as .mask file\n",
    "        #path1 = r\"drive/MyDrive/Glottis/masks/\" + str(vi) + \".mask\" # TODO: Set path\n",
    "        path1 = r\"drive/MyDrive/Glottis/GlottisNetV1/masks/40.mask\" # TODO: Set path\n",
    "\n",
    "        fl.save(path1, {\"mask\": masks, 'files': ims_orig}, compression='blosc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1nu2-dBy8qa76eFsmy6CRas8PhTqjHHRA"
    },
    "executionInfo": {
     "elapsed": 3239,
     "status": "ok",
     "timestamp": 1700942457954,
     "user": {
      "displayName": "Voice Production Laboratory",
      "userId": "06343012582981241924"
     },
     "user_tz": 180
    },
    "id": "sYdDaKrB4ply",
    "outputId": "bf57c33b-9d99-409d-ed81-d309e7023aaa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "# Ruta al archivo .mask que deseas visualizar\n",
    "mask_file_path = \"drive/MyDrive/Glottis/GlottisNetV1/masks/40.mask\"  # Asegúrate de ajustar la ruta según tu ubicación\n",
    "\n",
    "# Cargar el archivo .mask\n",
    "data = fl.load(mask_file_path)\n",
    "\n",
    "# Obtener las máscaras y las imágenes originales\n",
    "masks = data[\"mask\"]\n",
    "images = data[\"files\"]\n",
    "\n",
    "# Iterar a través de las máscaras y mostrarlas junto con las imágenes originales\n",
    "for i in range(len(masks)):\n",
    "    # Escala la máscara para que sea más visible (puedes ajustar la escala según tus necesidades)\n",
    "    scaled_mask = (masks[i] * 255).astype(np.uint8)\n",
    "\n",
    "    # Muestra la imagen original y la máscara utilizando cv2_imshow\n",
    "    cv2_imshow(images[i])\n",
    "    cv2_imshow(scaled_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1a6NShC_lCGG7Cvz4ep4aub6dgeIcsqIV"
    },
    "executionInfo": {
     "elapsed": 3096,
     "status": "ok",
     "timestamp": 1700879798104,
     "user": {
      "displayName": "Voice Production Laboratory",
      "userId": "06343012582981241924"
     },
     "user_tz": 180
    },
    "id": "QcLiliwel7y7",
    "outputId": "1cf14ba3-8963-4ee9-9496-affa71923afb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab.patches import cv2_imshow\n",
    "import flammkuchen as fl\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Esta función encuentra contornos en la máscara y dibuja los contornos en la imagen original\n",
    "def draw_contours_on_image(mask, img_orig, contour_color=(255, 255, 255)):\n",
    "    # Find contours in the mask\n",
    "    contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Create a copy of the original image\n",
    "    img_with_contours = img_orig.copy()\n",
    "\n",
    "    # Draw the contours on the original image using the specified contour_color\n",
    "    cv2.drawContours(img_with_contours, contours, -1, contour_color, 2)\n",
    "\n",
    "    return img_with_contours\n",
    "\n",
    "\n",
    "# Configurar los parámetros del video\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Puedes ajustar el códec según tus preferencias\n",
    "# Inicializar las dimensiones de ancho y alto\n",
    "ancho, alto = None, None\n",
    "\n",
    "# Crear el objeto de video sin dimensiones (se configurarán más tarde)\n",
    "output_video = None\n",
    "\n",
    "# Ruta al archivo .mask que deseas visualizar\n",
    "mask_file_path = \"drive/MyDrive/Glottis/GlottisNetV1/masks/40.mask\"  # Asegúrate de ajustar la ruta según tu ubicación\n",
    "\n",
    "# Cargar el archivo .mask\n",
    "data = fl.load(mask_file_path)\n",
    "\n",
    "# Obtener las máscaras y las imágenes originales\n",
    "masks = data[\"mask\"]\n",
    "images = data[\"files\"]\n",
    "\n",
    "for i in range(len(masks)):\n",
    "    # Llama a la función para dibujar contornos\n",
    "    img_with_contours = draw_contours_on_image(masks[i], images[i])\n",
    "\n",
    "    # Convertir la imagen a 8 bits sin signo si no lo está ya\n",
    "    if img_with_contours.dtype != np.uint8:\n",
    "        img_with_contours = img_with_contours.astype(np.uint8)\n",
    "\n",
    "    # Verificar si las dimensiones del video se han configurado\n",
    "    if ancho is None or alto is None:\n",
    "        alto, ancho = img_with_contours.shape[:2]\n",
    "        # Crear el objeto de video con las dimensiones de la imagen\n",
    "        output_video = cv2.VideoWriter('output_video.mp4', fourcc, 30, (ancho, alto))\n",
    "\n",
    "    # Agregar la imagen con contornos al video\n",
    "    output_video.write(img_with_contours)\n",
    "\n",
    "    # Mostrar la imagen con los contornos utilizando cv2_imshow\n",
    "    cv2_imshow(img_with_contours)\n",
    "\n",
    "output_video.release()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M31BZuuQCTKq"
   },
   "outputs": [],
   "source": [
    "import flammkuchen as fl\n",
    "import cv2\n",
    "import os\n",
    "import imageio as io\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow_addons as tfa\n",
    "def find_max_point(pred_map):\n",
    "    \"\"\"\n",
    "    Encuentra el punto con la mayor probabilidad en el mapa de predicción.\n",
    "    \"\"\"\n",
    "    y, x = np.unravel_index(np.argmax(pred_map), pred_map.shape)\n",
    "    return (x, y)\n",
    "\n",
    "def draw_line(img, point1, point2, color=(0, 255, 0), thickness=2):\n",
    "    \"\"\"\n",
    "    Dibuja una línea entre dos puntos.\n",
    "    \"\"\"\n",
    "    cv2.line(img, point1, point2, color, thickness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 252,
     "status": "ok",
     "timestamp": 1700945608705,
     "user": {
      "displayName": "Voice Production Laboratory",
      "userId": "06343012582981241924"
     },
     "user_tz": 180
    },
    "id": "uDsU7mnfQjQi",
    "outputId": "6f5e4e2b-f4bb-4e2d-f361-5f950fb78e73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de pred_maps: (1, 512, 256, 2)\n"
     ]
    }
   ],
   "source": [
    "# Justo después de la predicción, añade:\n",
    "print(\"Forma de pred_maps:\", pred_maps.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1dl51l9_WUbyKknJdtMHA0pSEIiJGmBWN"
    },
    "executionInfo": {
     "elapsed": 2247,
     "status": "ok",
     "timestamp": 1700946012013,
     "user": {
      "displayName": "Voice Production Laboratory",
      "userId": "06343012582981241924"
     },
     "user_tz": 180
    },
    "id": "MttfjnrFCJIU",
    "outputId": "ca53f359-6dc4-4c8a-8c78-e87c128ce907"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import flammkuchen as fl\n",
    "import cv2\n",
    "import numpy as np\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "def draw_contours_and_line(img_orig, mask, anterior_point, posterior_point, contour_color=(255, 255, 255), line_color=(0, 255, 0), line_thickness=2):\n",
    "    # Encuentra contornos en la máscara\n",
    "    contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Crea una copia de la imagen original\n",
    "    img_with_contours = img_orig.copy()\n",
    "\n",
    "    # Dibuja los contornos en la imagen original\n",
    "    cv2.drawContours(img_with_contours, contours, -1, contour_color, 2)\n",
    "\n",
    "    # Dibuja la línea media\n",
    "    cv2.line(img_with_contours, anterior_point, posterior_point, line_color, line_thickness)\n",
    "\n",
    "    return img_with_contours\n",
    "\n",
    "\n",
    "# ... (las funciones draw_contours_and_line y otras funciones quedan iguales) ...\n",
    "\n",
    "# Ruta al archivo .mask que deseas visualizar\n",
    "mask_file_path = \"drive/MyDrive/Glottis/GlottisNetV1/masks/40.mask\"\n",
    "\n",
    "# Cargar el archivo .mask\n",
    "data = fl.load(mask_file_path)\n",
    "masks = data[\"mask\"]\n",
    "images = data[\"files\"]\n",
    "\n",
    "# Configurar los parámetros del video de salida\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "output_video = None\n",
    "\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "# ... (resto del código anterior) ...\n",
    "\n",
    "for i, mask in enumerate(masks):\n",
    "    # ... (el código para obtener pred_maps y dibujar los contornos y la línea media) ...\n",
    "\n",
    "    # Asegúrate de que la imagen es del tipo correcto antes de guardarla\n",
    "    if img_with_contours_and_line.dtype != np.uint8:\n",
    "        img_with_contours_and_line = (img_with_contours_and_line * 255).astype(np.uint8)\n",
    "\n",
    "    # Inicializa el objeto de video si aún no se ha hecho\n",
    "    if output_video is None:\n",
    "        alto, ancho = img_with_contours_and_line.shape[:2]\n",
    "        output_video = cv2.VideoWriter('output_video.mp4', fourcc, 30, (ancho, alto))\n",
    "\n",
    "    output_video.write(img_with_contours_and_line)\n",
    "\n",
    "    # Utiliza cv2_imshow en Google Colab\n",
    "    cv2_imshow(img_with_contours_and_line)\n",
    "\n",
    "# Limpieza no es necesaria aquí, ya que cv2_imshow no crea ventanas adicionales\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
